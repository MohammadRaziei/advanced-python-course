{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69fbc152",
   "metadata": {},
   "source": [
    "\n",
    "# 🎓 Introduction to Gradio\n",
    "\n",
    "Gradio is an open-source Python library that enables you to quickly create user-friendly web interfaces for your machine learning models or any Python functions. It supports various input and output components, such as text, images, and audio, allowing for interactive demonstrations and applications.\n",
    "\n",
    "---\n",
    "\n",
    "## 📦 Installation\n",
    "\n",
    "Before we begin, ensure you have Gradio installed:\n",
    "\n",
    "```bash\n",
    "pip install gradio\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Understanding Gradio's Core Concepts\n",
    "\n",
    "- **Interface**: The primary class in Gradio used to create simple interfaces.\n",
    "- **Components**: Building blocks like `Textbox`, `Image`, and `Audio` that serve as inputs and outputs.\n",
    "- **Function (`fn`)**: The Python function that processes inputs and returns outputs.\n",
    "- **Launch**: Method to start the Gradio app and open it in a web browser.\n",
    "\n",
    "---\n",
    "\n",
    "## 📝 Text Input and Output\n",
    "\n",
    "Let's start with a simple example that takes text input and returns a greeting.\n",
    "\n",
    "```python\n",
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    return f\"Hello, {name}!\"\n",
    "\n",
    "demo = gr.Interface(fn=greet, inputs=gr.Textbox(label=\"Enter your name\"), outputs=gr.Textbox(label=\"Greeting\"))\n",
    "demo.launch()\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "- `gr.Textbox`: Creates a text input/output component.\n",
    "- The `greet` function takes the input text and returns a greeting message.\n",
    "\n",
    "---\n",
    "\n",
    "## 🖼️ Image Input and Output\n",
    "\n",
    "Now, let's create an interface that processes an image. For demonstration, we'll convert an image to grayscale.\n",
    "\n",
    "```python\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def to_grayscale(image):\n",
    "    return image.convert(\"L\")\n",
    "\n",
    "demo = gr.Interface(fn=to_grayscale, inputs=gr.Image(type=\"pil\", label=\"Upload Image\"), outputs=gr.Image(type=\"pil\", label=\"Grayscale Image\"))\n",
    "demo.launch()\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "- `gr.Image`: Handles image input/output. The `type=\"pil\"` parameter ensures the image is processed as a PIL Image object.\n",
    "- The `to_grayscale` function converts the uploaded image to grayscale.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔊 Audio Input and Output\n",
    "\n",
    "Let's build an interface that takes an audio input and returns the same audio. This example can be extended to include audio processing like noise reduction or speech recognition.\n",
    "\n",
    "```python\n",
    "import gradio as gr\n",
    "\n",
    "def echo(audio):\n",
    "    return audio\n",
    "\n",
    "demo = gr.Interface(fn=echo, inputs=gr.Audio(source=\"upload\", type=\"filepath\", label=\"Upload Audio\"), outputs=gr.Audio(label=\"Output Audio\"))\n",
    "demo.launch()\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "- `gr.Audio`: Manages audio input/output. `source=\"upload\"` allows users to upload audio files.\n",
    "- The `echo` function returns the same audio without modification.\n",
    "\n",
    "---\n",
    "\n",
    "## 🎛️ Combining Multiple Inputs and Outputs\n",
    "\n",
    "Gradio allows combining multiple input and output components. Here's an example that takes text and an image, and returns a modified image with the text overlayed.\n",
    "\n",
    "```python\n",
    "import gradio as gr\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def overlay_text(image, text):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # Get image dimensions\n",
    "    width, height = image.size\n",
    "    \n",
    "    # Calculate font size based on image dimensions (e.g., 5% of the smaller dimension)\n",
    "    font_size = int(min(width, height) * 0.05)\n",
    "    \n",
    "    # Use a TrueType font with adjustable size\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
    "    except IOError:\n",
    "        # Fallback to default if arial is not available\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    # Get text size (using getbbox or getsize depending on Pillow version)\n",
    "    try:\n",
    "        # For newer Pillow versions\n",
    "        left, top, right, bottom = font.getbbox(text)\n",
    "        text_width = right - left\n",
    "        text_height = bottom - top\n",
    "    except AttributeError:\n",
    "        # For older Pillow versions\n",
    "        text_width, text_height = draw.textsize(text, font=font)\n",
    "    \n",
    "    # Calculate center position\n",
    "    x = (width - text_width) // 2\n",
    "    y = (height - text_height) // 2\n",
    "    \n",
    "    # Draw text at center\n",
    "    draw.text((x, y), text, font=font, fill=\"red\")\n",
    "    return image\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=overlay_text,\n",
    "    inputs=[gr.Image(type=\"pil\", label=\"Upload Image\"), gr.Textbox(label=\"Enter Text\")],\n",
    "    outputs=gr.Image(type=\"pil\", label=\"Image with Text\")\n",
    ")\n",
    "demo.launch()\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "- Multiple inputs are passed as a list to the `inputs` parameter.\n",
    "- The `overlay_text` function draws the input text onto the uploaded image.\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 Sharing Your Gradio App\n",
    "\n",
    "To share your Gradio app with others, set the `share` parameter to `True` in the `launch` method:\n",
    "\n",
    "```python\n",
    "demo.launch(share=True)\n",
    "```\n",
    "\n",
    "This will generate a public URL that you can share, allowing others to interact with your app without needing to run the code locally.\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 Additional Resources\n",
    "\n",
    "For more information and advanced usage, refer to the official Gradio documentation: [https://www.gradio.app/docs](https://www.gradio.app/docs)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d055fb",
   "metadata": {},
   "source": [
    "\n",
    "# 🎛️ Gradio Layout with `Blocks`, `Row`, and `Column`\n",
    "\n",
    "---\n",
    "\n",
    "## 🧱 What Are Blocks?\n",
    "\n",
    "Gradio’s `Blocks` API lets you:\n",
    "\n",
    "- Combine multiple inputs/outputs in a **custom layout**\n",
    "- Use components in **rows** and **columns**\n",
    "- Update output **interactively** with buttons, sliders, events, etc.\n",
    "\n",
    "> Think of it like building a GUI with Lego blocks!\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Basic Structure\n",
    "\n",
    "```python\n",
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        gr.Textbox(label=\"Left\")\n",
    "        gr.Textbox(label=\"Right\")\n",
    "    with gr.Column():\n",
    "        gr.Button(\"Button 1\")\n",
    "        gr.Button(\"Button 2\")\n",
    "\n",
    "demo.launch()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 Full Example: Text + Image + Audio in Row/Column Layout\n",
    "\n",
    "```python\n",
    "import gradio as gr\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "\n",
    "def process(text, image, audio):\n",
    "    # Put text on image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.text((10, 10), text, fill=\"white\")\n",
    "    return image, audio, f\"Echo: {text}\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## 🧠 Multi-Modal Interface: Text, Image, Audio\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            txt = gr.Textbox(label=\"Enter text\")\n",
    "            img = gr.Image(type=\"pil\", label=\"Upload image\")\n",
    "            audio = gr.Audio(source=\"upload\", type=\"filepath\", label=\"Upload audio\")\n",
    "            btn = gr.Button(\"Run\")\n",
    "\n",
    "        with gr.Column():\n",
    "            out_img = gr.Image(label=\"Image with Text\")\n",
    "            out_audio = gr.Audio(label=\"Returned Audio\")\n",
    "            out_text = gr.Textbox(label=\"Text Output\")\n",
    "\n",
    "    btn.click(fn=process, inputs=[txt, img, audio], outputs=[out_img, out_audio, out_text])\n",
    "\n",
    "demo.launch()\n",
    "```\n",
    "\n",
    "#### Another Example:\n",
    "\n",
    "```python\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# 🎯 Fake Voice Activity Detection (VAD) Function\n",
    "def voice_activity_detection(audio_path):\n",
    "    # Generate random start and end times to simulate detected speech segments\n",
    "    starts = [round(random.uniform(0, 10), 2) for _ in range(3)]\n",
    "    ends = [start + round(random.uniform(0.5, 2), 2) for start in starts]\n",
    "\n",
    "    # Create a DataFrame to display results\n",
    "    df = pd.DataFrame({\n",
    "        \"start\": starts,\n",
    "        \"end\": ends\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# 🧱 Gradio Interface with Layout (Blocks, Rows, and Columns)\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## 🎤 Voice Activity Detection (Fake Example)\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            # Input audio component (uploaded from user)\n",
    "            audio_input = gr.Audio(source=\"upload\", type=\"filepath\", label=\"Upload audio file\")\n",
    "\n",
    "            # Button to trigger the processing function\n",
    "            btn = gr.Button(\"Run VAD\")\n",
    "\n",
    "        with gr.Column():\n",
    "            # Output table (DataFrame) to display VAD segments\n",
    "            output_df = gr.Dataframe(headers=[\"start\", \"end\"], label=\"Detected Speech Segments\")\n",
    "\n",
    "    # Bind button click to the VAD function\n",
    "    btn.click(fn=voice_activity_detection, inputs=audio_input, outputs=output_df)\n",
    "\n",
    "# Launch the interface\n",
    "demo.launch()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📐 Layout Guide\n",
    "\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| `gr.Blocks()` | Container for the full layout |\n",
    "| `gr.Row()`    | Horizontal container (left to right) |\n",
    "| `gr.Column()` | Vertical container (top to bottom) |\n",
    "| Nesting      | You can nest rows inside columns and vice versa |\n",
    "\n",
    "---\n",
    "\n",
    "## ✨ Bonus: Add Header/Footer with `gr.Markdown`\n",
    "\n",
    "```python\n",
    "gr.Markdown(\"# 🌟 My Fancy Gradio App\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Summary\n",
    "\n",
    "| Feature       | Benefit                                |\n",
    "|---------------|-----------------------------------------|\n",
    "| `Blocks`      | Full layout control                     |\n",
    "| `Row`         | Place components horizontally           |\n",
    "| `Column`      | Place components vertically             |\n",
    "| `.click()`    | Attach logic to buttons and events      |\n",
    "| Reusable      | Great for dashboards and complex UIs    |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
